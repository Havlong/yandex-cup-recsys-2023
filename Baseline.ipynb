{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "340aceb6-4360-49ac-8381-bb42055d6146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32801790-6619-4141-b909-a70de5e00071",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_DEV = 0\n",
    "NUM_TAGS = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f35090-eb3d-464b-b46f-de30c4d42d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b46b7d4b-785e-4187-b2bc-6c620c7b8cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 76714/76714 [00:34<00:00, 2235.27it/s]\n"
     ]
    }
   ],
   "source": [
    "track_idx2embeds = {}\n",
    "for fn in tqdm(glob('track_embeddings/*')):\n",
    "    track_idx = int(fn.split('/')[1].split('.')[0])\n",
    "    embeds = np.load(fn)\n",
    "    track_idx2embeds[track_idx] = embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d1b5cae-60ae-4584-a6bb-4f6b833929aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggingDataset(Dataset):\n",
    "    def __init__(self, df, testing=False):\n",
    "        self.df = df\n",
    "        self.testing = testing\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        track_idx = row.track\n",
    "        embeds = track_idx2embeds[track_idx]\n",
    "        if self.testing:\n",
    "            return track_idx, embeds\n",
    "        tags = [int(x) for x in row.tags.split(',')]\n",
    "        target = np.zeros(NUM_TAGS)\n",
    "        target[tags] = 1\n",
    "        return track_idx, embeds, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca9ac5cf-a481-4918-bbeb-ecf077c681ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TaggingDataset(df_train)\n",
    "test_dataset = TaggingDataset(df_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31c659b7-ee4b-44da-a715-b7abced07279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes = NUM_TAGS,\n",
    "        input_dim = 768,\n",
    "        hidden_dim = 512\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.bn = nn.LayerNorm(hidden_dim)\n",
    "        self.projector =  nn.Linear(input_dim, hidden_dim)\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, embeds):\n",
    "        x = [self.projector(x) for x in embeds]\n",
    "        x = [v.mean(0).unsqueeze(0) for v in x]\n",
    "        x = self.bn(torch.cat(x, dim = 0))\n",
    "        x = self.lin(x)\n",
    "        outs = self.fc(x)\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c70bf034-7966-4f44-9f2e-dcaf0f8a8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = None\n",
    "    alpha = 0.8\n",
    "    for iteration,data in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        track_idxs, embeds, target = data\n",
    "        embeds = [x.to(CUDA_DEV) for x in embeds]\n",
    "        target = target.to(CUDA_DEV)\n",
    "        pred_logits = model(embeds)\n",
    "        pred_probs = torch.sigmoid(pred_logits)\n",
    "        ce_loss = criterion(pred_logits, target)\n",
    "        ce_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if running_loss is None:\n",
    "            running_loss = ce_loss.item()\n",
    "        else:\n",
    "            running_loss = alpha * ce_loss.item() + (1 - alpha) * ce_loss.item()\n",
    "        if iteration % 100 == 0:\n",
    "            print('   {} batch {} loss {}'.format(\n",
    "                datetime.now(), iteration + 1, running_loss\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e624b0b-8daf-4702-a5de-c667fcd53121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    track_idxs = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            track_idx, embeds = data\n",
    "            embeds = [x.to(CUDA_DEV) for x in embeds]\n",
    "            pred_logits = model(embeds)\n",
    "            pred_probs = torch.sigmoid(pred_logits)\n",
    "            predictions.append(pred_probs.cpu().numpy())\n",
    "            track_idxs.append(track_idx.numpy())\n",
    "    predictions = np.vstack(predictions)\n",
    "    track_idxs = np.vstack(track_idxs).ravel()\n",
    "    return track_idxs, predictions\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4decde5-005a-4820-804c-cf4d110c799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(b):\n",
    "    track_idxs = torch.from_numpy(np.vstack([x[0] for x in b]))\n",
    "    embeds = [torch.from_numpy(x[1]) for x in b]\n",
    "    targets = np.vstack([x[2] for x in b])\n",
    "    targets = torch.from_numpy(targets)\n",
    "    return track_idxs, embeds, targets\n",
    "\n",
    "def collate_fn_test(b):\n",
    "    track_idxs = torch.from_numpy(np.vstack([x[0] for x in b]))\n",
    "    embeds = [torch.from_numpy(x[1]) for x in b]\n",
    "    return track_idxs, embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62124a85-3bcc-4eb8-a0d7-931c8685d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "448ff0ee-2a61-4761-8d54-8b555bca7a09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                             | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2023-10-18 14:44:16.531065 batch 1 loss 0.7075236743025073\n",
      "   2023-10-18 14:44:19.635338 batch 101 loss 0.061150574771176025\n",
      "   2023-10-18 14:44:22.648454 batch 201 loss 0.06005757680158297\n",
      "   2023-10-18 14:44:25.647729 batch 301 loss 0.05305281765681258\n",
      "   2023-10-18 14:44:28.865557 batch 401 loss 0.049346572020205315\n",
      "   2023-10-18 14:44:32.195140 batch 501 loss 0.057245233538916196\n",
      "   2023-10-18 14:44:35.263436 batch 601 loss 0.05244400113768144\n",
      "   2023-10-18 14:44:38.268890 batch 701 loss 0.05683685487486079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████████▏                                                                                | 1/5 [00:24<01:39, 24.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2023-10-18 14:44:41.407519 batch 1 loss 0.051108709063606206\n",
      "   2023-10-18 14:44:44.591685 batch 101 loss 0.05333008464301092\n",
      "   2023-10-18 14:44:47.672684 batch 201 loss 0.048615851497457285\n",
      "   2023-10-18 14:44:50.802449 batch 301 loss 0.0583331023006981\n",
      "   2023-10-18 14:44:53.968967 batch 401 loss 0.05178474290641466\n",
      "   2023-10-18 14:44:57.164127 batch 501 loss 0.05326607791981397\n",
      "   2023-10-18 14:45:00.310902 batch 601 loss 0.052663159237691326\n",
      "   2023-10-18 14:45:03.410570 batch 701 loss 0.04468915274223273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████████████▍                                                            | 2/5 [00:49<01:15, 25.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2023-10-18 14:45:06.484146 batch 1 loss 0.04721943227215725\n",
      "   2023-10-18 14:45:09.541661 batch 101 loss 0.050256302482861726\n",
      "   2023-10-18 14:45:12.575161 batch 201 loss 0.05486756705535234\n",
      "   2023-10-18 14:45:15.564876 batch 301 loss 0.049959886820693106\n",
      "   2023-10-18 14:45:18.597967 batch 401 loss 0.05274463129892182\n",
      "   2023-10-18 14:45:21.635723 batch 501 loss 0.04564777213306273\n",
      "   2023-10-18 14:45:24.656053 batch 601 loss 0.04729849403013675\n",
      "   2023-10-18 14:45:27.692837 batch 701 loss 0.04419671735428721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████████████████▌                                        | 3/5 [01:14<00:49, 24.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2023-10-18 14:45:30.730044 batch 1 loss 0.04981377498281575\n",
      "   2023-10-18 14:45:33.805331 batch 101 loss 0.04552920163440567\n",
      "   2023-10-18 14:45:36.847583 batch 201 loss 0.04601334920829567\n",
      "   2023-10-18 14:45:40.143551 batch 301 loss 0.044677905001484636\n",
      "   2023-10-18 14:45:43.349172 batch 401 loss 0.04973384967735042\n",
      "   2023-10-18 14:45:46.447115 batch 501 loss 0.04973694900626728\n",
      "   2023-10-18 14:45:49.506476 batch 601 loss 0.04558426338107989\n",
      "   2023-10-18 14:45:52.578888 batch 701 loss 0.04347101551451775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████████████████████▊                    | 4/5 [01:39<00:24, 24.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2023-10-18 14:45:55.722427 batch 1 loss 0.045827866771364995\n",
      "   2023-10-18 14:45:59.347741 batch 101 loss 0.05284176830913666\n",
      "   2023-10-18 14:46:03.010142 batch 201 loss 0.04611076906422269\n",
      "   2023-10-18 14:46:06.190025 batch 301 loss 0.04525545036523977\n",
      "   2023-10-18 14:46:09.216547 batch 401 loss 0.04345847934989745\n",
      "   2023-10-18 14:46:12.213595 batch 501 loss 0.0521099605665411\n",
      "   2023-10-18 14:46:15.181224 batch 601 loss 0.04785939400439373\n",
      "   2023-10-18 14:46:18.164844 batch 701 loss 0.045106463558975664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:04<00:00, 24.93s/it]\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "epochs = 5\n",
    "model = model.to(CUDA_DEV)\n",
    "criterion = criterion.to(CUDA_DEV)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_epoch(model, train_dataloader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a65faa1-76ff-4329-aadf-65594c8f577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_idxs, predictions = predict(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70f38f54-5bdc-4b24-b711-83aa87f1f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame([\n",
    "    {'track': track, 'prediction': ','.join([str(p) for p in probs])}\n",
    "    for track, probs in zip(track_idxs, predictions)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "810b0804-c39b-4cb3-9a00-fb443a8aa734",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
